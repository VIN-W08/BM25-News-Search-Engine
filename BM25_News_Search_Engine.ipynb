{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BM25 News Search Engine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUhFPciyIL6z",
        "outputId": "a2e74140-9739-4f44-8bf5-7a65b4342fc8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "nltk.download(\"wordnet\")\r\n",
        "from nltk.corpus import wordnet\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "import re\r\n",
        "import math\r\n",
        "from collections import Counter"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjJKq_MJISbt",
        "outputId": "cb2acdca-636a-4419-99ca-c4cfcfb4f9dd"
      },
      "source": [
        "dataset = pd.read_json(\"News_Category_Dataset_v2.json\", lines=True)\r\n",
        "df = dataset[[\"category\",\"headline\",\"short_description\"]]\r\n",
        "df.head(5)\r\n",
        "\r\n",
        "print(np.unique(np.array(df[\"category\"]))) # 42 categories"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ARTS' 'ARTS & CULTURE' 'BLACK VOICES' 'BUSINESS' 'COLLEGE' 'COMEDY'\n",
            " 'CRIME' 'CULTURE & ARTS' 'DIVORCE' 'EDUCATION' 'ENTERTAINMENT'\n",
            " 'ENVIRONMENT' 'FIFTY' 'FOOD & DRINK' 'GOOD NEWS' 'GREEN' 'HEALTHY LIVING'\n",
            " 'HOME & LIVING' 'IMPACT' 'LATINO VOICES' 'MEDIA' 'MONEY' 'PARENTING'\n",
            " 'PARENTS' 'POLITICS' 'QUEER VOICES' 'RELIGION' 'SCIENCE' 'SPORTS' 'STYLE'\n",
            " 'STYLE & BEAUTY' 'TASTE' 'TECH' 'THE WORLDPOST' 'TRAVEL' 'WEDDINGS'\n",
            " 'WEIRD NEWS' 'WELLNESS' 'WOMEN' 'WORLD NEWS' 'WORLDPOST']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKT-syGqQF50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e12708-e7d3-4d43-df1e-08a45f30d51b"
      },
      "source": [
        "df = dataset[[\"category\",\"headline\",\"short_description\"]]\r\n",
        "\r\n",
        "# find not alphabet in \"headline\" column\r\n",
        "foundNotAlphaHeadline = []\r\n",
        "for row in df[\"headline\"]:\r\n",
        "  foundNotAlphaHeadline = foundNotAlphaHeadline + re.findall(\"[^a-zA-Z0-9 ]\",row)\r\n",
        "\r\n",
        "foundNotAlphaHeadline = np.unique(np.array(foundNotAlphaHeadline))\r\n",
        "print(\"Not Alphabet in 'Headline' column:\\n\",foundNotAlphaHeadline)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not Alphabet in 'Headline' column:\n",
            " ['\\t' '!' '\"' '#' '$' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.' '/' ':' ';'\n",
            " '=' '>' '?' '@' '[' '\\\\' ']' '^' '_' '{' '|' '}' '~' '\\x7f' '\\xa0' '¡'\n",
            " '¢' '£' '©' '«' '\\xad' '®' '¯' '°' '´' '·' '½' '¿' 'À' 'Ç' 'É' 'Ñ' 'Ü'\n",
            " 'à' 'á' 'â' 'ã' 'ä' 'å' 'ç' 'è' 'é' 'ê' 'ë' 'ì' 'í' 'î' 'ï' 'ñ' 'ó' 'ô'\n",
            " 'ö' 'ø' 'ù' 'ú' 'û' 'ü' 'ā' 'ć' 'Č' 'ğ' 'œ' 'ś' 'ū' 'ů' 'ž' 'ǒ' 'ș' 'ʻ'\n",
            " 'ʼ' 'Έ' 'Κ' 'ά' 'ί' 'α' 'γ' 'δ' 'ε' 'η' 'ι' 'κ' 'λ' 'μ' 'ν' 'ξ' 'ο' 'ρ'\n",
            " 'ς' 'σ' 'τ' 'υ' 'ω' 'ό' 'ύ' 'ώ' 'ᴥ' 'ᵒ' 'ᶅ' 'ᶘ' 'ạ' 'ấ' 'ễ' '\\u2009'\n",
            " '\\u200a' '\\u200b' '\\u200e' '\\u200f' '‐' '–' '—' '―' '‘' '’' '“' '”' '…'\n",
            " '\\u2028' '′' '™' '⊙' '◕' 'ツ' '︿' '\\ufeff' 'ﾩ' 'ﾫ' 'ￃ' '🌮' '🌷' '🌿' '🍂' '🍃'\n",
            " '💯']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcc47F_93W0F",
        "outputId": "06a2ffc6-a03b-44b1-bd45-f90f0b6b852c"
      },
      "source": [
        "# find not alphabet in \"short_description\" column\r\n",
        "foundNotAlphaDesc = []\r\n",
        "for row in df[\"short_description\"]:\r\n",
        "  foundNotAlphaDesc = foundNotAlphaDesc + re.findall(\"[^a-zA-Z0-9 ]\",row)\r\n",
        "\r\n",
        "foundNotAlphaDesc = np.unique(np.array(foundNotAlphaDesc))\r\n",
        "print(\"Not Alphabet in 'short_description' column:\\n\",foundNotAlphaDesc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not Alphabet in 'short_description' column:\n",
            " ['\\t' '\\n' '!' '\"' '#' '$' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.' '/' ':'\n",
            " ';' '=' '>' '?' '@' '[' '\\\\' ']' '^' '_' '`' '{' '|' '}' '~' '\\x80'\n",
            " '\\x93' '\\x94' '\\x99' '\\xa0' '¡' '£' '©' '¬' '\\xad' '®' '¯' '°' '±' '´'\n",
            " '·' '¹' 'º' '¼' '½' '¾' '¿' 'Á' 'Å' 'Ç' 'É' 'Î' 'Ö' '×' 'Ø' 'Ü' 'à' 'á'\n",
            " 'â' 'ã' 'ä' 'å' 'æ' 'ç' 'è' 'é' 'ê' 'ë' 'ì' 'í' 'î' 'ï' 'ñ' 'ò' 'ó' 'ô'\n",
            " 'ö' 'ø' 'ù' 'ú' 'û' 'ü' 'ý' 'ā' 'ć' 'Č' 'č' 'ē' 'ė' 'ğ' 'ī' 'Ł' 'ł' 'ń'\n",
            " 'ō' 'œ' 'Ş' 'ş' 'š' 'ū' 'ű' 'ž' 'ș' 'ə' 'ɛ' 'ɪ' 'ʼ' 'ˈ' 'ˌ' 'ː' '˚' '̀'\n",
            " '́' 'η' 'Г' 'Ж' 'П' 'а' 'б' 'в' 'г' 'е' 'з' 'и' 'к' 'л' 'м' 'н' 'о' 'п'\n",
            " 'р' 'с' 'т' 'у' 'ф' 'х' 'ы' 'ь' 'я' 'ِ' 'আ' 'ই' 'গ' 'ট' 'ভ' 'র' 'ল' 'স'\n",
            " 'া' 'ি' 'ো' '্' 'ಠ' 'ầ' 'ễ' '\\u200a' '\\u200b' '\\u200d' '\\u200e' '\\u200f'\n",
            " '‐' '‒' '–' '—' '―' '‘' '’' '‚' '“' '”' '•' '…' '\\u2028' '\\u202a'\n",
            " '\\u202c' '\\u202f' '′' '″' '‹' '›' '€' '™' '≠' '②' '─' '☀' '☂' '☃' '☔' '☕'\n",
            " '☘' '☼' '♂' '♥' '♦' '♫' '♬' '⚡' '⚾' '⛄' '⛱' '⛽' '✂' '✈' '✊' '✌' '✔' '✨'\n",
            " '❄' '❤' '➡' 'ツ' '象' 'ﬁ' 'ﬂ' '️' '\\ufeff' 'ﾨ' 'ﾩ' 'ﾴ' 'ￃ' '￼' '�' '🇦' '🇨'\n",
            " '🇫' '🇬' '🇭' '🇵' '🇷' '🇸' '🇺' '🇿' '🌈' '🌊' '🌍' '🌎' '🌑' '🌒' '🌓' '🌔' '🌕' '🌖'\n",
            " '🌗' '🌘' '🌝' '🌞' '🌤' '🌦' '🌮' '🌳' '🌴' '🌸' '🌹' '🍁' '🍂' '🍃' '🍅' '🍆' '🍋' '🍌'\n",
            " '🍍' '🍎' '🍑' '🍒' '🍓' '🍔' '🍕' '🍖' '🍗' '🍜' '🍝' '🍞' '🍟' '🍦' '🍩' '🍪' '🍫' '🍭'\n",
            " '🍰' '🍴' '🍷' '🍸' '🍹' '🍻' '🍽' '🍾' '🎀' '🎁' '🎂' '🎃' '🎄' '🎅' '🎆' '🎇' '🎈' '🎉'\n",
            " '🎊' '🎓' '🎤' '🎨' '🎭' '🎮' '🎵' '🎶' '🎸' '🎾' '🏀' '🏃' '🏅' '🏆' '🏈' '🏊' '🏨' '🏫'\n",
            " '🏰' '🏼' '🏽' '🏾' '🐊' '🐋' '🐍' '🐎' '🐔' '🐘' '🐛' '🐝' '🐥' '🐬' '🐭' '🐮' '🐱' '🐲'\n",
            " '🐳' '🐶' '🐷' '🐸' '🐼' '🐾' '👀' '👅' '👊' '👋' '👌' '👍' '👏' '👑' '👓' '👖' '👚' '👠'\n",
            " '👩' '👪' '👬' '👭' '👯' '👰' '👴' '👵' '👶' '👹' '👻' '👼' '👽' '💀' '💁' '💃' '💄' '💅'\n",
            " '💇' '💉' '💊' '💋' '💍' '💎' '💐' '💔' '💕' '💖' '💗' '💘' '💙' '💚' '💛' '💜' '💞' '💡'\n",
            " '💤' '💥' '💦' '💧' '💨' '💩' '💪' '💫' '💯' '💰' '💸' '💻' '💼' '📚' '📝' '📱' '📷' '📸'\n",
            " '📺' '🔋' '🔍' '🔑' '🔥' '🔪' '🔮' '🕵' '🕺' '🗣' '😀' '😁' '😂' '😃' '😇' '😈' '😉' '😊'\n",
            " '😍' '😎' '😏' '😐' '😑' '😒' '😔' '😕' '😘' '😜' '😞' '😠' '😡' '😢' '😩' '😬' '😭' '😮'\n",
            " '😰' '😱' '😳' '😴' '😵' '😶' '😷' '😻' '🙀' '🙂' '🙃' '🙄' '🙅' '🙆' '🙈' '🙊' '🙌' '🙏'\n",
            " '🚀' '🚂' '🚇' '🚗' '🚨' '🚬' '🚴' '🛀' '🤑' '🤓' '🤔' '🤗' '🤘' '🤢' '🤦' '🤼' '🥂' '🥗'\n",
            " '🦄' '🦈']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHiOZFzscK6g"
      },
      "source": [
        "def removeNotAlpha(sentence, column):\r\n",
        "  if (column == \"headline\"):\r\n",
        "    for na in foundNotAlphaHeadline:\r\n",
        "      sentence = sentence.replace(na,\"\")\r\n",
        "\r\n",
        "  elif (column == \"short_description\"):\r\n",
        "    for na in foundNotAlphaDesc:\r\n",
        "      sentence = sentence.replace(na,\"\")\r\n",
        "  \r\n",
        "  elif (column == \"query\"):\r\n",
        "    for na in foundNotAlphaDesc:\r\n",
        "      sentence = sentence.replace(na,\"\")\r\n",
        "\r\n",
        "  return sentence\r\n",
        "\r\n",
        "def toLower(sentence):\r\n",
        "  return sentence.lower()\r\n",
        "\r\n",
        "apostrophes = [\"’s\",\"’ll\",\"’re\",\"’m\",\"n’t\",\"’d\",\"'s\",\"'ll\",\"'re\",\"'m\",\"n't\",\"'d\"]\r\n",
        "def removeApostrophes(sentence):\r\n",
        "  for ap in apostrophes:\r\n",
        "    sentence = sentence.replace(ap,\"\")\r\n",
        "  return sentence\r\n",
        "\r\n",
        "def getWordNetPOS(term):\r\n",
        "  tag = nltk.pos_tag([term])[0][1][0].upper()\r\n",
        "  tag_dict = {\r\n",
        "      \"J\": wordnet.ADJ,\r\n",
        "      \"N\": wordnet.NOUN,\r\n",
        "      \"V\": wordnet.VERB,\r\n",
        "      \"R\": wordnet.ADV}\r\n",
        "\r\n",
        "  return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "pattern = re.compile(\"[[a-zA-z0-9]*]?[0-9][[a-zA-z0-9]*]?\")\r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "def lemmatization(sentence):\r\n",
        "  words = sentence.split()\r\n",
        "  lemmatized_word = list(map(lambda word: lemmatizer.lemmatize(word, getWordNetPOS(word)) if (pattern.match(word) == None) else word, words))\r\n",
        "  return \" \".join(lemmatized_word)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "uwIQvl7BddkN",
        "outputId": "1f6ebd6c-cee3-435a-dbc8-6ffbbd0f6d7d"
      },
      "source": [
        "for idx in range(df.shape[0]):\r\n",
        "  headl = df[\"headline\"][idx]\r\n",
        "  desc = df[\"short_description\"][idx]\r\n",
        "\r\n",
        "  headl = removeNotAlpha(headl, \"headline\")\r\n",
        "  desc = removeNotAlpha(desc, \"short_description\")\r\n",
        "\r\n",
        "  headl = toLower(headl)\r\n",
        "  desc = toLower(desc)\r\n",
        "  \r\n",
        "  headl = removeApostrophes(headl)\r\n",
        "  desc = removeApostrophes(desc)\r\n",
        "\r\n",
        "  headl = lemmatization(headl)\r\n",
        "  desc = lemmatization(desc)\r\n",
        "\r\n",
        "  df[\"category\"][idx] = toLower(df[\"category\"][idx])\r\n",
        "  df[\"headline\"][idx] = headl\r\n",
        "  df[\"short_description\"][idx] = desc\r\n",
        "\r\n",
        "df.head(8)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>short_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>crime</td>\n",
              "      <td>there be 2 mass shooting in texas last week bu...</td>\n",
              "      <td>she left her husband he kill their child just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>will smith join diplo and nicky jam for the 20...</td>\n",
              "      <td>of course it have a song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>hugh grant marries for the first time at age 57</td>\n",
              "      <td>the actor and his longtime girlfriend anna ebe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>jim carrey blast castrato adam schiff and demo...</td>\n",
              "      <td>the actor give dems an asskicking for not figh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>julianna margulies us donald trump poop bag to...</td>\n",
              "      <td>the dietland actress say use the bag be a real...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>morgan freeman devastate that sexual harassmen...</td>\n",
              "      <td>it be not right to equate horrific incident of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>donald trump be lovin new mcdonalds jingle in ...</td>\n",
              "      <td>it catchy all right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>what to watch on amazon prime thats new this week</td>\n",
              "      <td>there a great miniseries join this week</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category  ...                                  short_description\n",
              "0          crime  ...  she left her husband he kill their child just ...\n",
              "1  entertainment  ...                           of course it have a song\n",
              "2  entertainment  ...  the actor and his longtime girlfriend anna ebe...\n",
              "3  entertainment  ...  the actor give dems an asskicking for not figh...\n",
              "4  entertainment  ...  the dietland actress say use the bag be a real...\n",
              "5  entertainment  ...  it be not right to equate horrific incident of...\n",
              "6  entertainment  ...                                it catchy all right\n",
              "7  entertainment  ...            there a great miniseries join this week\n",
              "\n",
              "[8 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Fx8pRcDQG4-0",
        "outputId": "0f339f4a-13ab-4323-c088-2c674126d8fb"
      },
      "source": [
        "data = pd.DataFrame({\r\n",
        "    \"headline\": df[\"headline\"],\r\n",
        "     \"body\": df[\"category\"] +\" \"+df[\"headline\"]+\" \"+df[\"short_description\"]})\r\n",
        "\r\n",
        "data.head(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>there be 2 mass shooting in texas last week bu...</td>\n",
              "      <td>crime there be 2 mass shooting in texas last w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>will smith join diplo and nicky jam for the 20...</td>\n",
              "      <td>entertainment will smith join diplo and nicky ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hugh grant marries for the first time at age 57</td>\n",
              "      <td>entertainment hugh grant marries for the first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jim carrey blast castrato adam schiff and demo...</td>\n",
              "      <td>entertainment jim carrey blast castrato adam s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>julianna margulies us donald trump poop bag to...</td>\n",
              "      <td>entertainment julianna margulies us donald tru...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline                                               body\n",
              "0  there be 2 mass shooting in texas last week bu...  crime there be 2 mass shooting in texas last w...\n",
              "1  will smith join diplo and nicky jam for the 20...  entertainment will smith join diplo and nicky ...\n",
              "2    hugh grant marries for the first time at age 57  entertainment hugh grant marries for the first...\n",
              "3  jim carrey blast castrato adam schiff and demo...  entertainment jim carrey blast castrato adam s...\n",
              "4  julianna margulies us donald trump poop bag to...  entertainment julianna margulies us donald tru..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHPyKFXSJ0Rd"
      },
      "source": [
        "# Input Query\r\n",
        "query = \"crime in texas\"\r\n",
        "\r\n",
        "q_data = removeNotAlpha(query,\"query\")\r\n",
        "q_data = toLower(q_data)\r\n",
        "q_data = removeApostrophes(q_data)\r\n",
        "q_data = lemmatization(q_data)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_HzhxyUKKpO"
      },
      "source": [
        "def countTF(term):\r\n",
        "  tf = {}\r\n",
        "  idx = 0\r\n",
        "  for doc in data.iloc():\r\n",
        "    body = doc[\"body\"].split()\r\n",
        "    tf[doc[\"headline\"]] = body.count(term) + 1 # +1 to avoid zero division\r\n",
        "\r\n",
        "  return tf\r\n",
        "\r\n",
        "def countDF(term):\r\n",
        "  count = 0\r\n",
        "  for doc in data[\"body\"]:\r\n",
        "    if((term in doc) == True):\r\n",
        "      count = count + 1\r\n",
        "  return count\r\n",
        "\r\n",
        "def countDocLength():\r\n",
        "  lengths = {}\r\n",
        "  for doc in data.iloc():\r\n",
        "    lengths[doc[\"headline\"]] = len(doc[\"body\"].split())\r\n",
        "  \r\n",
        "  return lengths\r\n",
        "\r\n",
        "# calculate BM23 score for each term\r\n",
        "def calculateEachScore(term):\r\n",
        "  docNum = data.shape[0]\r\n",
        "  docLength = countDocLength()\r\n",
        "  docAvgLength = sum(list(docLength.values()))/len(list(docLength.values()))\r\n",
        "  tf = countTF(term)\r\n",
        "  df = countDF(term)\r\n",
        "  idf = math.log10((docNum - df + 0.5)/(df + 0.5))\r\n",
        "  k = 2\r\n",
        "  b = 0.75\r\n",
        "\r\n",
        "  score = {}\r\n",
        "  for doc in data.iloc():\r\n",
        "    score[doc[\"headline\"]] = ((tf[doc[\"headline\"]] * (k + 1)) / (tf[doc[\"headline\"]] + k * (1 - b + b * docLength[doc[\"headline\"]] / docAvgLength))) * idf\r\n",
        "\r\n",
        "  return score\r\n",
        "\r\n",
        "# calculate BM23 score for each body\r\n",
        "def calculateScore(query):\r\n",
        "  terms = query.split()\r\n",
        "  score = {}\r\n",
        "  for term in terms:\r\n",
        "    score = dict(Counter(score) + Counter(calculateEachScore(term)))\r\n",
        "  \r\n",
        "  return score"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZKsP3du0_S2"
      },
      "source": [
        "# sort output by score descending\r\n",
        "output = sorted(calculateScore(q_data).items(), key=lambda item: item[1], reverse=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "jM058PClrDr2",
        "outputId": "c3c904ef-92f1-433b-bfd9-f50d09d40215"
      },
      "source": [
        "# Results\r\n",
        "output = pd.DataFrame(output, columns = [\"News\", \"BM25 Score\"])\r\n",
        "output.head(6)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "      <th>BM25 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>texas serial shooter wont stop</td>\n",
              "      <td>7.353313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>texas prisoner still face deadly heat report</td>\n",
              "      <td>7.125399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hundred of inmate relocate after texas prison ...</td>\n",
              "      <td>7.016326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>texas massacre suspect have previous domestic ...</td>\n",
              "      <td>7.016326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fatal alligator attack in texas</td>\n",
              "      <td>6.997810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>texas executes first inmate with new batch of ...</td>\n",
              "      <td>6.910348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                News  BM25 Score\n",
              "0                     texas serial shooter wont stop    7.353313\n",
              "1       texas prisoner still face deadly heat report    7.125399\n",
              "2  hundred of inmate relocate after texas prison ...    7.016326\n",
              "3  texas massacre suspect have previous domestic ...    7.016326\n",
              "4                    fatal alligator attack in texas    6.997810\n",
              "5  texas executes first inmate with new batch of ...    6.910348"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}